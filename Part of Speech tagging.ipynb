{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"The quick brown fox jumped over the lazy dog's back.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quick brown fox jumped over the lazy dog's back.\n"
     ]
    }
   ],
   "source": [
    "#here we print out the text in doc\n",
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VBD\n"
     ]
    }
   ],
   "source": [
    "#if  I want to pick a particular token position like the word jumped indexing then i do \n",
    "#i can also call various part of this token for example i can grab the SPEECH TAG with (doc[4].pos_) wich give out VERB\n",
    "#or if you want the Fine_grained PArt-of-speech Tags as determined by morphology i type (doc[4].tag_)wich give out VBD\n",
    "#so VERB + VBD  means verb and past tense. so that means that the word \"jumped\" is Past Tense.\n",
    "#if you leave away the underscore it shows then always the numerical ID ( 1710900183.....) for that particular tag.\n",
    "print(doc[4].tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The        DET        15267657372422890137 determiner\n",
      "quick      ADJ        10554686591937588953 adjective\n",
      "brown      ADJ        10554686591937588953 adjective\n",
      "fox        NOUN       15308085513773655218 noun, singular or mass\n",
      "jumped     VERB       17109001835818727656 verb, past tense\n",
      "over       ADP        1292078113972184607 conjunction, subordinating or preposition\n",
      "the        DET        15267657372422890137 determiner\n",
      "lazy       ADJ        10554686591937588953 adjective\n",
      "dog        NOUN       15308085513773655218 noun, singular or mass\n",
      "'s         PART               74 possessive ending\n",
      "back       NOUN       15308085513773655218 noun, singular or mass\n",
      ".          PUNCT      12646065887601541794 punctuation mark, sentence closer\n"
     ]
    }
   ],
   "source": [
    "#now i can make a little for loop and by saying for token an document\n",
    "#print out all of this little table with all the information using f string literals. so i can say now :\n",
    "#print out the token text, token.text , print out token part of speech, token.pos, print out token tag, token.tag \n",
    "#print out an explanation, spacy.explain(token.tag_)\n",
    "#\n",
    "for token in doc:\n",
    "    print(f\"{token.text:{10}} {token.pos_:{10}} {token.tag:{10}} {spacy.explain(token.tag_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so i just made the coarse green part of speech tags as well as the fine grained part of speech\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now in the English language as we mention that same string of characters can have different meanings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"I am a teacher.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = doc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'am'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "am         VERB       9188597074677201817 verb, non-3rd person singular present\n"
     ]
    }
   ],
   "source": [
    "#Here it shows that the word am is present tense\n",
    "word = doc[1]\n",
    "token = word\n",
    "print(f\"{token.text:{10}} {token.pos_:{10}} {token.tag:{10}} {spacy.explain(token.tag_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"I was a teacher.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "was        VERB       17109001835818727656 verb, past tense\n"
     ]
    }
   ],
   "source": [
    "#here it recognizes that the word was is past tense\n",
    "word = doc[1]\n",
    "token = word\n",
    "print(f\"{token.text:{10}} {token.pos_:{10}} {token.tag:{10}} {spacy.explain(token.tag_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so lets do actuall count parts of speech tags. So the document object has a count by a method that accepts a specific \n",
    "#token attribute as its argument and then it return a frequency count of the given attribute as a dictionary object.\n",
    "#here is an example\n",
    "doc = nlp(u\"The quick brown fox jumped over the lazy dog's back.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_counts = doc.count_by(spacy.attrs.POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{90: 2, 84: 3, 92: 3, 100: 1, 85: 1, 94: 1, 97: 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#thes numbers are actuall part of speech code 90 , 84 etc normaly when we do the underscore example: token.pos_ we will get\n",
    "# the tag like VERB but without the underscore we will get back the numerical identifier.\n",
    "#I also see now the counts like 2 , 3, 3, 1 etc..these a re values counts how often it occurs in the sentence\n",
    "POS_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ADJ'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So I can always lookup the numerical identifier for.ex. 96, 83, 99, etc simply by calling the documents vocab and then\n",
    "#passing in whatever number we are interested in, let's say 83 and then ask for the text of that and I'll return back thats\n",
    "#an adjective again ADJ\n",
    "doc.vocab[84].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#i recall that if we just grab any token off of a document. doc[2].pos_ ADJ, or just doc[2].pos it shows 83 \n",
    "#thats what a speech of counts doing, its returning back the number and then how many times it showed up\n",
    "#so there are 3 Adjectives ADJ in this document \"the Quick brown fox.......\"\n",
    "doc[2].pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOW IF YOU WANT TO ACTUALLY CREATE A FREQUENCY LIST OF SPEECH TAGS FROM THE ENTIRE DOCUMENT YOU CAN DO THAT BY SIMPLE making a \n",
    "FOR LOOP THAT LOOKS SIMILAR LIKE THIS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84. ADJ   3\n",
      "85. ADP   1\n",
      "90. DET   2\n",
      "92. NOUN  3\n",
      "94. PART  1\n",
      "97. PUNCT 1\n",
      "100. VERB  1\n"
     ]
    }
   ],
   "source": [
    "#I can say for k,v key value in that we can call sorted sorted() POS counts items wich is essentially a list of tulpes\n",
    "#i print out with a little formatting here to look nice table we print ut the {k}\n",
    "for k,v in sorted(POS_counts.items()):\n",
    "    print(f\"{k}. {doc.vocab[k].text:{5}} {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above result gives me the informatino that for example ADJ with the numerical ID 84 occurs 3 times in our Doc sentence.\n",
    "you can do this also not just for speech tags but for the fine grained tags as well.\n",
    "this i will show you below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74. POS   1\n",
      "1292078113972184607. IN    1\n",
      "10554686591937588953. JJ    3\n",
      "12646065887601541794. .     1\n",
      "15267657372422890137. DT    2\n",
      "15308085513773655218. NN    3\n",
      "17109001835818727656. VBD   1\n"
     ]
    }
   ],
   "source": [
    "#instead of POS counts we say TAG counts\n",
    "#and lets create that Tag counts object\n",
    "TAG_counts = doc.count_by(spacy.attrs.TAG)\n",
    "for k,v in sorted(TAG_counts.items()):\n",
    "    print(f\"{k}. {doc.vocab[k].text:{5}} {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402. amod  3\n",
      "415. det   2\n",
      "429. nsubj 1\n",
      "439. pobj  1\n",
      "440. poss  1\n",
      "443. prep  1\n",
      "445. punct 1\n",
      "8110129090154140942. case  1\n",
      "8206900633647566924. ROOT  1\n"
     ]
    }
   ],
   "source": [
    "#and then we can do it also for DEP \n",
    "DEP_counts = doc.count_by(spacy.attrs.DEP)\n",
    "for k,v in sorted(DEP_counts.items()):\n",
    "    print(f\"{k}. {doc.vocab[k].text:{5}} {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
